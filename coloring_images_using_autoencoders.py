# -*- coding: utf-8 -*-
"""Coloring Images using Autoencoders.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19UTaP58H8UK_eKTn2IXmTwCdUH4z6DRy
"""

!unzip /content/drive/MyDrive/Kaggle/image_colorization/data.zip

import tensorflow as tf
from skimage.color import rgb2lab, lab2rgb, gray2rgb, rgb2gray
from skimage.transform import resize
from skimage.io import imsave
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Conv2D, UpSampling2D, Input
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
import os

len(os.listdir("data/"))

from tensorflow.keras.applications.vgg16 import VGG16
vggmodel = VGG16()
vggmodel.summary()

def read_image_gray_2(filepath):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_image(image, channels=3)
    image = resize(image, output_shape=(224, 224))
    image_grey = rgb2gray(image)
    return image, image_grey

inputForModel = []
outputForModel = []


for img_path in os.listdir("data/"):
    try:
        path = "data/" + img_path
        img, gray_img = read_image_gray_2(path)
        inputForModel.append(gray2rgb(gray_img))
        outputForModel.append(img)
    except:
        continue

inputForModel = np.array(inputForModel)
outputForModel = np.array(outputForModel)

inputForModel.shape, outputForModel.shape

inputForModel.min(), inputForModel.max()

outputForModel.min(), outputForModel.max()

plt.imshow(inputForModel[19])

plt.imshow(outputForModel[19])

rgbmodel = Sequential()

for i, layer in enumerate(vggmodel.layers):
    if i<19:
        rgbmodel.add(layer)

for layer in rgbmodel.layers:
    layer.trainable = False

rgbmodel.add(Conv2D(256, (3,3), activation='relu', padding='same', input_shape=(7,7,512)))
rgbmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))
rgbmodel.add(UpSampling2D((2, 2)))
rgbmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))
rgbmodel.add(UpSampling2D((2, 2)))
rgbmodel.add(Conv2D(32, (3,3), activation='relu', padding='same'))
rgbmodel.add(UpSampling2D((2, 2)))
rgbmodel.add(Conv2D(16, (3,3), activation='relu', padding='same'))
rgbmodel.add(UpSampling2D((2, 2)))
rgbmodel.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))
rgbmodel.add(UpSampling2D((2, 2)))
rgbmodel.summary()

rgbmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),
              loss = tf.keras.losses.BinaryCrossentropy(),
              metrics=["accuracy"])

historyrgb = rgbmodel.fit(inputForModel, outputForModel, epochs=1000, batch_size=32)

plt.plot(historyrgb.history['loss'])

plt.plot(historyrgb.history['accuracy'])

colored, gray = read_image_gray_2("/content/data/Cityscapes_Image_1.jpg")

plt.imshow(colored)

gray_image = gray2rgb(gray)
print(gray_image.shape)
plt.imshow(gray_image)

gray_image_input = np.expand_dims(gray_image, axis=0)
gray_image_input.shape

colored_image_prediction = rgbmodel.predict(gray_image_input)
colored_image_prediction.shape

plt.imshow(np.squeeze(colored_image_prediction))

rgbmodel2 = Sequential()

for i, layer in enumerate(vggmodel.layers):
    if i<19:
        rgbmodel2.add(layer)

for layer in rgbmodel2.layers:
    layer.trainable = False

rgbmodel2.add(Conv2D(256, (3,3), activation='relu', padding='same', input_shape=(7,7,512)))
rgbmodel2.add(Conv2D(128, (3,3), activation='relu', padding='same'))
rgbmodel2.add(UpSampling2D((2, 2)))
rgbmodel2.add(Conv2D(64, (3,3), activation='relu', padding='same'))
rgbmodel2.add(UpSampling2D((2, 2)))
rgbmodel2.add(Conv2D(32, (3,3), activation='relu', padding='same'))
rgbmodel2.add(UpSampling2D((2, 2)))
rgbmodel2.add(Conv2D(16, (3,3), activation='relu', padding='same'))
rgbmodel2.add(UpSampling2D((2, 2)))
rgbmodel2.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))
rgbmodel2.add(UpSampling2D((2, 2)))
rgbmodel2.summary()

rgbmodel2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss = tf.keras.losses.BinaryCrossentropy(),
              metrics=["accuracy"])

historyrgb2 = rgbmodel2.fit(inputForModel, outputForModel, epochs=1000, batch_size=32)

def read_image_lab(filepath):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_image(image, channels=3)
    image = resize(image, output_shape=(224, 224))
    image = rgb2lab(image)
    return image

i = read_image_lab("/content/data/Cityscapes_Image_1.jpg")

l = gray2rgb(i[:, :, 0]/100.)
ab = i[:, :, 1:]/128.

l.shape, ab.shape

x = np.zeros((224,224,3))

x[:, :, 0] = l[:, :, 0]*100.
x[:, :, 1:] = ab*128.

plt.imshow(lab2rgb(x))

X = []
Y = []

for img_path in os.listdir("data/"):
    try:
        path = "data/" + img_path
        img = read_image_lab(path)
        l = gray2rgb(img[:, :, 0]/100.)
        ab = img[:, :, 1:]/128.
        X.append(l)
        Y.append(ab)
    except:
        continue

X = np.array(X)
Y = np.array(Y)

X.shape, Y.shape

Y.min(), Y.max()

labmodel = Sequential()

for i, layer in enumerate(vggmodel.layers):
    if i<19:
        labmodel.add(layer)

for layer in labmodel.layers:
    layer.trainable = False

labmodel.add(Conv2D(256, (3,3), activation='relu', padding='same', input_shape=(7,7,512)))
labmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))
labmodel.add(UpSampling2D((2, 2)))
labmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))
labmodel.add(UpSampling2D((2, 2)))
labmodel.add(Conv2D(32, (3,3), activation='relu', padding='same'))
labmodel.add(UpSampling2D((2, 2)))
labmodel.add(Conv2D(16, (3,3), activation='relu', padding='same'))
labmodel.add(UpSampling2D((2, 2)))
labmodel.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))
labmodel.add(UpSampling2D((2, 2)))
labmodel.summary()

labmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),
              loss = tf.keras.losses.MeanSquaredError(),
              metrics=["accuracy"])

historylab = labmodel.fit(X, Y, epochs=1000, batch_size=32, validation_split=0.2)

historylab.history.keys()

plt.figure(figsize=(15,8))
plt.plot(historylab.history["loss"], color='blue')
plt.plot(historylab.history["val_loss"], color='red')
plt.legend(['loss','val_loss'])

plt.figure(figsize=(15,8))
plt.plot(historylab.history["accuracy"], color='blue')
plt.plot(historylab.history["val_accuracy"], color='red')
plt.legend(['accuracy','val_accuracy'])

predictions = labmodel.predict(X)

predictions.shape

predim = []

for i, im in enumerate(X):
    image = np.zeros((224, 224, 3))
    image[:, :, 0] = im[:, :, 0]*100.
    image[:, :, 1:] = predictions[i, :, :, :]*128.

    image = lab2rgb(image)
    predim.append(image)

predim = np.array(predim)
predim.shape

predictions.max(), predictions.min()

plt.imshow(predim[160])

plt.imshow(X[160])

plt.imshow(predim[19])

plt.imshow(X[19])

def prepare_image_for_lab_model(filepath):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_image(image, channels=3)
    image = resize(image, output_shape=(224, 224))
    image = rgb2lab(image)
    image = image[:, :, 0]/100.
    image = gray2rgb(image)
    return image

image_input = prepare_image_for_lab_model("/content/photo-1493928841026-e1ab0a590a61.jpg")
plt.imshow(image_input)

pred_image = labmodel.predict(np.expand_dims(image_input, axis=0))
pred_image = np.squeeze(pred_image)

x = np.zeros((224, 224, 3))
x[:, :, 0] = image_input[:, :, 0]*100. 
x[:, :, 1:] = pred_image * 128.

pred_image = lab2rgb(x)
plt.imshow(pred_image)

labmodel.save("labmodel")

!zip -r labmodel.zip /content/labmodel

loadedmodel = tf.keras.models.load_model("/content/labmodel")

loadedmodel.summary()

loadedmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),
              loss = tf.keras.losses.BinaryCrossentropy(),
              metrics=["accuracy"])

historyloadedmodel = loadedmodel.fit(X, Y, epochs=100, batch_size=32, validation_split=0.2)

